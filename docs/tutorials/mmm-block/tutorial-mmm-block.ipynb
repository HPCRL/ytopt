{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: Autotune the OpenMP version of XSBench \n",
    "===================\n",
    "\n",
    "This tutorial describes how to define autotuning problem and an evaluating method for autotuning the block matrix multiplication. \n",
    "\n",
    "We assume that you have checked out a copy of `ytopt`. For guidelines on how to get ytopt set up, refer [Install instructions](https://github.com/ytopt-team/ytopt/blob/tutorial/README.md). \n",
    "\n",
    "This example including the source code is borrowed from [http://opentuner.org/tutorial/gettingstarted/](http://opentuner.org/tutorial/gettingstarted/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indentifying a problem to autotune \n",
    "-----------------------\n",
    "In this tutorial, we target to autotune the block size for matrix multiplication. Save the related source files in the seprate folder: `mmm_block.cpp`. For your convenience, we have the files in `<https://github.com/ytopt-team/ytopt/tree/tutorial/ytopt/benchmark/mmm-block/mmm_problem/mmm_block.cpp>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <cstdlib>\n",
    "\n",
    "#define N 100\n",
    "\n",
    "int main(int argc, const char** argv)\n",
    "{\n",
    "\n",
    "  int n = BLOCK_SIZE * (N/BLOCK_SIZE);\n",
    "  int a[N][N];\n",
    "  int b[N][N];\n",
    "  int c[N][N];\n",
    "  int sum=0;\n",
    "  for(int k1=0;k1<n;k1+=BLOCK_SIZE)\n",
    "  {\n",
    "      for(int j1=0;j1<n;j1+=BLOCK_SIZE)\n",
    "      {\n",
    "          for(int k1=0;k1<n;k1+=BLOCK_SIZE)\n",
    "          {\n",
    "              for(int i=0;i<n;i++)\n",
    "              {\n",
    "                  for(int j=j1;j<j1+BLOCK_SIZE;j++)\n",
    "                  {\n",
    "                      sum = c[i][j];\n",
    "                      for(int k=k1;k<k1+BLOCK_SIZE;k++)\n",
    "                      {               \n",
    "                          sum += a[i][k] * b[k][j];\n",
    "                      }\n",
    "                      c[i][j] = sum;\n",
    "                  }\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "         }\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining autotuning problem\n",
    "-----------------------\n",
    "We describe how to define your search problem `<https://github.com/ytopt-team/ytopt/blob/tutorial/ytopt/benchmark/mmm-block/mmm_problem/problem.py>`\n",
    "\n",
    "--------------\n",
    "First, we first define search space using ConfigSpace that is a python library `<https://automl.github.io/ConfigSpace/master/>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required library\n",
    "import os, sys, time, json, math\n",
    "import numpy as np\n",
    "from autotune import TuningProblem\n",
    "from autotune.space import *\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our search space contains one parameter; `BLOCK_SIZE`: number of blocks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of ConfigSpace\n",
    "cs = CS.ConfigurationSpace(seed=1234)\n",
    "#block size for openmp dynamic schedule\n",
    "p0= CSH.OrdinalHyperparameter(name='BLOCK_SIZE', sequence=['1','2','3','4','5','6','7','8','9','10'], default_value='5')\n",
    "cs.add_hyperparameters([p0])\n",
    "# problem space\n",
    "input_space = cs\n",
    "output_space = Space([Real(0.0, inf, name=\"time\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "Then, we need to define the objective function to evaluate a point in the search space. \n",
    "\n",
    "In this example, we define an evaluating method (Plopper) for code generation and compilation. \n",
    "Plopper take source code and output directory and return an execution time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "kernel_idx = dir_path.rfind('/')\n",
    "kernel = dir_path[kernel_idx+1:]\n",
    "obj = Plopper(dir_path+'/mmm_block.cpp',dir_path)\n",
    "\n",
    "x1=['BLOCK_SIZE']\n",
    "def myobj(point: dict):\n",
    "    def plopper_func(x):\n",
    "        x = np.asarray_chkfinite(x)  # ValueError if any NaN or Inf\n",
    "        value = [point[x1[0]]]\n",
    "        print('CONFIG:',point)\n",
    "        params = [\"BLOCK_SIZE\"]\n",
    "        result = obj.findRuntime(value, params)\n",
    "        return result\n",
    "\n",
    "    x = np.array([point['BLOCK_SIZE']])\n",
    "    results = plopper_func(x)\n",
    "    print('OUTPUT:%f',results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following describes our evaluating function, Plopper. You can find it `<https://github.com/ytopt-team/ytopt/blob/tutorial/ytopt/benchmark/mmm-block/plopper/plopper.py>`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess, random\n",
    "random.seed(1234)\n",
    "\n",
    "class Plopper:\n",
    "    def __init__(self,sourcefile,outputdir):\n",
    "        self.sourcefile = sourcefile\n",
    "        self.outputdir = outputdir+\"/tmp_files\"\n",
    "\n",
    "        if not os.path.exists(self.outputdir):\n",
    "            os.makedirs(self.outputdir)\n",
    "\n",
    "    def createDict(self, x, params):\n",
    "        dictVal = {}\n",
    "        for p, v in zip(params, x):\n",
    "            dictVal[p] = v\n",
    "        return(dictVal)\n",
    "    \n",
    "    def findRuntime(self, x, params):\n",
    "        interimfile = \"\"\n",
    "        exetime = 1\n",
    "        \n",
    "        # Generate intermediate file\n",
    "        dictVal = self.createDict(x, params)\n",
    "\n",
    "        #compile and find the execution time\n",
    "        tmpbinary = self.outputdir + '/tmp.bin'\n",
    "        kernel_idx = self.sourcefile.rfind('/')\n",
    "        kernel_dir = self.sourcefile[:kernel_idx]\n",
    "        gcc_cmd = 'g++ ' + kernel_dir +'/mmm_block.cpp '\n",
    "        gcc_cmd += ' -D{0}={1}'.format('BLOCK_SIZE', dictVal['BLOCK_SIZE'])\n",
    "        gcc_cmd += ' -o ' + tmpbinary #+ kernel_dir + '/tmp.bin'\n",
    "        run_cmd = kernel_dir + \"/exe.pl \" + tmpbinary\n",
    "\n",
    "        #Find the compilation status using subprocess\n",
    "        compilation_status = subprocess.run(gcc_cmd, shell=True, stderr=subprocess.PIPE)\n",
    "\n",
    "        #Find the execution time only when the compilation return code is zero, else return infinity\n",
    "        if compilation_status.returncode == 0 :\n",
    "            execution_status = subprocess.run(run_cmd, shell=True, stdout=subprocess.PIPE)\n",
    "            exetime = float(execution_status.stdout.decode('utf-8'))\n",
    "            if exetime == 0:\n",
    "                exetime = 1\n",
    "        else:\n",
    "            print(compilation_status.stderr)\n",
    "            print(\"compile failed\")\n",
    "        return exetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file consists of several components.\n",
    "\n",
    "`__init__()` takes paths of the source file and output directory, and creates the output directory if it does not exists.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self,sourcefile,outputdir):\n",
    "    # Initilizing global variables\n",
    "    self.sourcefile = sourcefile\n",
    "    self.outputdir = outputdir+\"/tmp_files\"\n",
    "\n",
    "    if not os.path.exists(self.outputdir):\n",
    "        os.makedirs(self.outputdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`createDict()` generates a dictionary for parameter labels and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDict(self, x, params):\n",
    "    dictVal = {}\n",
    "    for p, v in zip(params, x):\n",
    "        dictVal[p] = v\n",
    "    return(dictVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`findRuntime()` first calls `createDict()` to obatain configuration. \n",
    "After that, it generates the commandline `gcc_cmd` for compiling the modified source code and the commandline `run_cmd` for executing the compiled code. \n",
    "Then, it finds the compilation status using subprocess; finds the execution time of the compiled code; and returns the execution time as cost to the search module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def findRuntime(self, x, params):\n",
    "        interimfile = \"\"\n",
    "        exetime = 1\n",
    "        \n",
    "        # Generate intermediate file\n",
    "        dictVal = self.createDict(x, params)\n",
    "\n",
    "        #compile and find the execution time\n",
    "        tmpbinary = self.outputdir + '/tmp.bin'\n",
    "        kernel_idx = self.sourcefile.rfind('/')\n",
    "        kernel_dir = self.sourcefile[:kernel_idx]\n",
    "        gcc_cmd = 'g++ ' + kernel_dir +'/mmm_block.cpp '\n",
    "        gcc_cmd += ' -D{0}={1}'.format('BLOCK_SIZE', dictVal['BLOCK_SIZE'])\n",
    "        gcc_cmd += ' -o ' + tmpbinary #+ kernel_dir + '/tmp.bin'\n",
    "        run_cmd = kernel_dir + \"/exe.pl \" + tmpbinary\n",
    "\n",
    "        #Find the compilation status using subprocess\n",
    "        compilation_status = subprocess.run(gcc_cmd, shell=True, stderr=subprocess.PIPE)\n",
    "\n",
    "        #Find the execution time only when the compilation return code is zero, else return infinity\n",
    "        if compilation_status.returncode == 0 :\n",
    "            execution_status = subprocess.run(run_cmd, shell=True, stdout=subprocess.PIPE)\n",
    "            exetime = float(execution_status.stdout.decode('utf-8'))\n",
    "            if exetime == 0:\n",
    "                exetime = 1\n",
    "        else:\n",
    "            print(compilation_status.stderr)\n",
    "            print(\"compile failed\")\n",
    "        return exetime #return execution time as cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "- `exe.pl` computes average the execution time over 5 runs. \n",
    "\n",
    "--------------\n",
    "Last, we create an object of the autotuning problem. The problem will be called in the commandline implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Problem = TuningProblem(\n",
    "    task_space=None,\n",
    "    input_space=input_space,\n",
    "    output_space=output_space,\n",
    "    objective=myobj,\n",
    "    constraints=None,\n",
    "    model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running and viewing Results\n",
    "-----------------------\n",
    "\n",
    "Now, we can run the following command to autotune our program: \n",
    "--evaluator flag sets which object used to evaluate models, --problem flag sets path to the Problem instance you want to use for the search, --max-evals flag sets the maximum number of evaluations, --learner flag sets the type of learner (surrogate model).\n",
    "\n",
    "`python -m ytopt.search.ambs --evaluator ray --problem ytopt.benchmark.mmm-block.mmm_problem.problem.Problem --max-evals=5 --learner RF\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "Once autotuning kick off, ytopt.log, results.csv, and results.json will be rendered.\n",
    "\n",
    "We can track the results of each run configuration from `ytopt.log` shows the following (output lines are truncated for readability here): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2021-07-28 15:51:49|2126|INFO|ytopt.search.search:53] Created \"ray\" evaluator\n",
    "2021-07-28 15:51:49|2126|INFO|ytopt.search.search:54] Evaluator: num_workers is 1\n",
    "2021-07-28 15:51:49|2126|INFO|ytopt.search.hps.ambs:47] Initializing AMBS\n",
    "2021-07-28 15:51:49|2126|INFO|ytopt.search.hps.optimizer.optimizer:51] Using skopt.Optimizer with RF base_estimator\n",
    "2021-07-28 15:51:49|2126|INFO|ytopt.search.hps.ambs:79] Generating 1 initial points...\n",
    "2021-07-28 15:51:50|2126|INFO|ytopt.evaluator.evaluate:104] Submitted new eval of {'p0': '6', 'p1': '200', 'p2': ' '}\n",
    "2021-07-28 15:52:12|2126|INFO|ytopt.evaluator.evaluate:206] New eval finished: {\"p0\": \"6\", \"p1\": \"200\", \"p2\": \" \"} --> 20.158\n",
    "2021-07-28 15:52:12|2126|INFO|ytopt.evaluator.evaluate:217] Requested eval x: {'p0': '6', 'p1': '200', 'p2': ' '} y: 20.158\n",
    "2021-07-28 15:52:12|2126|INFO|ytopt.search.hps.ambs:92] Refitting model with batch of 1 evals\n",
    "2021-07-28 15:52:12|2126|DEBUG|ytopt.search.hps.optimizer.optimizer:119] tell: {'p0': '6', 'p1': '200', 'p2': ' '} --> ('6', '200', ' '): evaluated objective: 20.158\n",
    "2021-07-28 15:52:13|2126|INFO|ytopt.search.hps.ambs:94] Drawing 1 points with strategy cl_max\n",
    "2021-07-28 15:52:13|2126|DEBUG|ytopt.search.hps.optimizer.optimizer:84] _ask: ['7', '40', ' '] lie: 20.158\n",
    "2021-07-28 15:52:13|2126|INFO|ytopt.evaluator.evaluate:104] Submitted new eval of {'p0': '7', 'p1': '40', 'p2': ' '}\n",
    "2021-07-28 15:52:36|2126|INFO|ytopt.evaluator.evaluate:206] New eval finished: {\"p0\": \"7\", \"p1\": \"40\", \"p2\": \" \"} --> 21.687\n",
    "2021-07-28 15:52:36|2126|INFO|ytopt.evaluator.evaluate:217] Requested eval x: {'p0': '7', 'p1': '40', 'p2': ' '} y: 21.687\n",
    "2021-07-28 15:52:36|2126|INFO|ytopt.search.hps.ambs:92] Refitting model with batch of 1 evals\n",
    "2021-07-28 15:52:36|2126|DEBUG|ytopt.search.hps.optimizer.optimizer:119] tell: {'p0': '7', 'p1': '40', 'p2': ' '} --> ('7', '40', ' '): evaluated objective: 21.687\n",
    "2021-07-28 15:52:37|2126|INFO|ytopt.search.hps.ambs:94] Drawing 1 points with strategy cl_max\n",
    "2021-07-28 15:52:37|2126|DEBUG|ytopt.search.hps.optimizer.optimizer:84] _ask: ['7', '200', '#pragma omp parallel for'] lie: 21.687\n",
    "2021-07-28 15:52:37|2126|INFO|ytopt.evaluator.evaluate:104] Submitted new eval of {'p0': '7', 'p1': '200', 'p2': '#pragma omp parallel for'}\n",
    "2021-07-28 15:52:58|2126|INFO|ytopt.evaluator.evaluate:206] New eval finished: {\"p0\": \"7\", \"p1\": \"200\", \"p2\": \"#pragma omp parallel for\"} --> 20.393\n",
    "2021-07-28 15:52:58|2126|INFO|ytopt.evaluator.evaluate:217] Requested eval x: {'p0': '7', 'p1': '200', 'p2': '#pragma omp parallel for'} y: 20.393\n",
    "2021-07-28 15:52:58|2126|INFO|ytopt.search.hps.ambs:92] Refitting model with batch of 1 evals\n",
    "2021-07-28 15:52:58|2126|DEBUG|ytopt.search.hps.optimizer.optimizer:119] tell: {'p0': '7', 'p1': '200', 'p2': '#pragma omp parallel for'} --> ('7', '200', '#pragma omp parallel for'): evaluated objective: 20.393\n",
    "2021-07-28 15:52:59|2126|INFO|ytopt.search.hps.ambs:94] Drawing 1 points with strategy cl_max\n",
    "2021-07-28 15:52:59|2126|DEBUG|ytopt.search.hps.optimizer.optimizer:84] _ask: ['8', '100', ' '] lie: 21.687\n",
    "2021-07-28 15:52:59|2126|INFO|ytopt.evaluator.evaluate:104] Submitted new eval of {'p0': '8', 'p1': '100', 'p2': ' '}\n",
    "2021-07-28 15:53:20|2126|INFO|ytopt.evaluator.evaluate:206] New eval finished: {\"p0\": \"8\", \"p1\": \"100\", \"p2\": \" \"} --> 20.577\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up the best configuration (found so far) and its value by inspecting the following created file: `results.csv` and `results.json`. \n",
    "\n",
    "In this run, the best configuration and its runtime is obtained:\n",
    "\n",
    "`{\"p0\": \"8\", \"p1\": \"200\", \"p2\": \"#pragma omp parallel for\"}: 19.604`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Reading\n",
    "--------------\n",
    "- `xxx <yyy>`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
